{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e729c",
   "metadata": {},
   "source": [
    "# Image Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5308bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3446e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY_REF = \"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\"\n",
    "\n",
    "# Encodes Image to Base64 so that the ai \n",
    "def encode_image_to_base64(image_path: str):\n",
    "    \"\"\"\n",
    "    Encodes Image to base64 encoding. \n",
    "    Input: image path\n",
    "    Output: Base64 encoded image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259b26b",
   "metadata": {},
   "source": [
    "# AI Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bb3557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai(prompt: str, img_files: str):\n",
    "    \"\"\"\n",
    "    Gets ai response for prompt\n",
    "    Input: Prompt and Path to Image\n",
    "    Output: AI response\n",
    "    \"\"\"\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY_REF}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Read and encode the image\n",
    "    image_path = img_files\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    data_url = f\"data:image/jpeg;base64,{base64_image}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": data_url\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/llama-4-maverick:free\",\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f5f09",
   "metadata": {},
   "source": [
    "# Image Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a32268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def take_picture(path_to_save: str ,port: int):\n",
    "    \"\"\"\n",
    "    Takes picture via camera\n",
    "    Input: Path to save the image and \n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(port)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        cv2.imwrite(path_to_save, frame)\n",
    "        print(\"Photo saved as \" + path_to_save)\n",
    "    else:\n",
    "        print(\"Failed to capture image\")\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f13cf6",
   "metadata": {},
   "source": [
    "# Prompt for Plant Name and water consuption in ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90114871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begonia x hiemalis\n"
     ]
    }
   ],
   "source": [
    "var1  = print(ai(\"\"\"What is in this image? eg if an apple is being shown then dont't describe it. just try to identify the apple and output the latin name only. \n",
    "         no other description or text of it. \n",
    "         also if you are only 100 percent sure, then only\"\"\",\"./images/uknown_plant.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb840bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(ai(f\"\"\"Please give me the water consumption in ml. If for example a plant needs 400ml of waters the output will be: 400. Don't give me text or any type of description or say anything except the number. If you fail to obey this you will be replaced by an better model. Only one number. Here is the name of the plant: {var1}\"\"\",\"./images/uknown_plant.jpeg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e47b66",
   "metadata": {},
   "source": [
    "# Number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac4f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of white pixels: 40\n",
      "Number of black pixels: 2655\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read the Image by giving path\n",
    "image = cv2.imread('./images/uknown_plant.jpeg')\n",
    "\n",
    "# display that image\n",
    "cv2.imshow(\"GG\", image) # type: ignore\n",
    "# counting the number of pixels\n",
    "number_of_white_pix = np.sum(image == 255)\n",
    "number_of_black_pix = np.sum(image == 0)\n",
    "\n",
    "print('Number of white pixels:', number_of_white_pix)\n",
    "print('Number of black pixels:', number_of_black_pix)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb49894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width in pixels: 1153, Height in pixels: 1531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread(\"./images/uknown_plant.jpeg\")\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # type: ignore\n",
    "\n",
    "_, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "c = max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "print(f\"Width in pixels: {w}, Height in pixels: {h}\")\n",
    "\n",
    "# Optional: draw rectangle\n",
    "cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2) # type: ignore\n",
    "cv2.imwrite(\"flower_measured.png\", image) # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49dff5",
   "metadata": {},
   "source": [
    "# Bildtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902722b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # Display the captured frame\n",
    "    cv2.imshow('Camera', frame)\n",
    "    \n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.imwrite(\"myimage.jpg\", frame)\n",
    "        break\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "moin = cv2.imread(\"myimage.jpg\")\n",
    "print(type(moin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3497093",
   "metadata": {},
   "source": [
    "# Calculate distance equivalence in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db5cd980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size (px): 640 x 480\n",
      "Detected red contour area (px^2): 25893\n",
      "Ruler pixel length (px): 223  (box_w, box_h)= 210 223\n",
      "Estimated focal length (pixels): 371.67\n",
      "Object size (estimated) -> width: 1551.1 mm, height: 2059.6 mm\n",
      "In cm -> width: 155.1 cm, height: 206.0 cm\n",
      "Wrote visualization to /mnt/data/ruler_detected.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- SETTINGS: adjust these ---\n",
    "img_path = \"./myimage.jpg\"  # your image path\n",
    "Z_cm = 50.0               # distance camera -> ruler in cm (you said ~50cm)\n",
    "real_ruler_length_mm = 300.0  # the real physical length of the ruler segment you will use (mm)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "Z_mm = Z_cm * 10.0  # cm -> mm\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Could not load image: {os.path.abspath(img_path)}\")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "print(\"Image size (px):\", w, \"x\", h)\n",
    "\n",
    "# Convert to HSV to mask red ruler\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# two red ranges (wrap-around)\n",
    "lower1 = np.array([0, 70, 50])\n",
    "upper1 = np.array([10, 255, 255])\n",
    "lower2 = np.array([170, 70, 50])\n",
    "upper2 = np.array([180, 255, 255])\n",
    "\n",
    "mask1 = cv2.inRange(hsv, lower1, upper1)\n",
    "mask2 = cv2.inRange(hsv, lower2, upper2)\n",
    "mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Morphological clean-up\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "# Find contours\n",
    "cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "if not cnts:\n",
    "    raise RuntimeError(\"No red contour (ruler) found. Adjust color thresholds or check image.\")\n",
    "\n",
    "# choose largest red contour\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "area = cv2.contourArea(c)\n",
    "print(\"Detected red contour area (px^2):\", int(area))\n",
    "\n",
    "# get minimum area rectangle -> gives width/height in px\n",
    "rect = cv2.minAreaRect(c)\n",
    "box = cv2.boxPoints(rect).astype(int)\n",
    "box_w = int(rect[1][0])\n",
    "box_h = int(rect[1][1])\n",
    "ruler_pixel_length = max(box_w, box_h)  # long side is the ruler length in px\n",
    "print(\"Ruler pixel length (px):\", ruler_pixel_length, \" (box_w, box_h)=\", box_w, box_h)\n",
    "\n",
    "# Compute focal length in pixels:\n",
    "f_px = (ruler_pixel_length * Z_mm) / real_ruler_length_mm\n",
    "print(f\"Estimated focal length (pixels): {f_px:.2f}\")\n",
    "\n",
    "# Example: convert an object measured in pixels (use your measured w,h)\n",
    "# Replace these two with measurements you already computed or compute here.\n",
    "object_pixel_width = 1153\n",
    "object_pixel_height = 1531\n",
    "\n",
    "real_width_mm = (object_pixel_width * Z_mm) / f_px\n",
    "real_height_mm = (object_pixel_height * Z_mm) / f_px\n",
    "\n",
    "print(f\"Object size (estimated) -> width: {real_width_mm:.1f} mm, height: {real_height_mm:.1f} mm\")\n",
    "print(f\"In cm -> width: {real_width_mm/10:.1f} cm, height: {real_height_mm/10:.1f} cm\")\n",
    "\n",
    "# Visualize detected ruler and bounding box (optional)\n",
    "vis = img.copy()\n",
    "cv2.drawContours(vis, [box], 0, (0,255,0), 2)\n",
    "cv2.putText(vis, f\"ruler_px={ruler_pixel_length}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "out_path = \"/mnt/data/ruler_detected.png\"\n",
    "cv2.imwrite(out_path, vis)\n",
    "print(\"Wrote visualization to\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13429d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Prath\\Programming\\esfz\\images\\ok.jpg: 384x640 1 potted plant, 246.9ms\n",
      "Speed: 5.8ms preprocess, 246.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([[168.3134,  33.3618, 909.3212, 707.6249]])\n",
      "741\n",
      "1280\n",
      "26.629968261718748\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "image = cv2.imread(\"./images/ok.jpg\")\n",
    "height, width, channels = image.shape # type: ignore\n",
    "\n",
    "\n",
    "results = model(\"./images/ok.jpg\")\n",
    "\n",
    "results[0].show()\n",
    "# Length\n",
    "print(results[0].boxes.xyxy)\n",
    "plantLength = abs(results[0].boxes.xyxy[0][0] - results[0].boxes.xyxy[0][2]) \n",
    "print(int(plantLength))\n",
    "print(int(width))\n",
    "\n",
    "realwidth = (float(plantLength) / float(width)) * 46\n",
    "print(realwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[168.3134,  33.3618, 909.3212, 707.6249]])\n",
      "674\n",
      "23.17779483795166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d41570ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Prath\\Programming\\esfz\\images\\ok2.jpg: 480x640 1 potted plant, 1 dining table, 1 cell phone, 1 book, 368.8ms\n",
      "Speed: 9.4ms preprocess, 368.8ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([[4.0116e+01, 4.8799e-01, 3.9066e+02, 2.5533e+02],\n",
      "        [5.7285e-01, 3.8852e+02, 3.0220e+02, 4.7974e+02],\n",
      "        [1.6982e+01, 1.7496e+02, 6.3863e+02, 4.8000e+02],\n",
      "        [1.9199e+02, 2.2303e+02, 5.1507e+02, 4.2739e+02]])\n",
      "350\n",
      "640\n",
      "25.195003890991213\n",
      "tensor([[4.0116e+01, 4.8799e-01, 3.9066e+02, 2.5533e+02],\n",
      "        [5.7285e-01, 3.8852e+02, 3.0220e+02, 4.7974e+02],\n",
      "        [1.6982e+01, 1.7496e+02, 6.3863e+02, 4.8000e+02],\n",
      "        [1.9199e+02, 2.2303e+02, 5.1507e+02, 4.2739e+02]])\n",
      "254\n",
      "17.520274925231934\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import cv2\n",
    "\n",
    "# Open the default camera\n",
    "cam = cv2.VideoCapture(2)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # Display the captured frame\n",
    "    cv2.imshow('Camera', frame)\n",
    "    \n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.imwrite(\"myimage.jpg\", frame)\n",
    "        break\n",
    "\n",
    "# Release the capture and writer objects\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "moin = cv2.imread(\"myimage.jpg\")\n",
    "print(type(moin))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(2)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "askIfReady = input(\"Have you turned the plant? (Yes/No)\")\n",
    "if askIfReady == \"yes\":\n",
    "    ret, frame = cam.read()\n",
    "    cv2.imwrite(\"images/ok2.jpg\", frame)\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    image = cv2.imread(\"./images/ok2.jpg\")\n",
    "    height, width, channels = image.shape # type: ignore\n",
    "    results = model(\"./images/ok2.jpg\")\n",
    "\n",
    "results[0].show()\n",
    "# Length\n",
    "print(results[0].boxes.xyxy)\n",
    "plantLength = abs(results[0].boxes.xyxy[0][0] - results[0].boxes.xyxy[0][2]) \n",
    "print(int(plantLength))\n",
    "print(int(width))\n",
    "\n",
    "realwidth = (float(plantLength) / float(width)) * 46\n",
    "print(realwidth)\n",
    "\n",
    "# Height\n",
    "print(results[0].boxes.xyxy)\n",
    "plantLength = abs(results[0].boxes.xyxy[0][1] - results[0].boxes.xyxy[0][3]) \n",
    "print(int(plantLength))\n",
    "\n",
    "realwidth = (float(plantLength) / float(width)) * 44\n",
    "print(realwidth)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
